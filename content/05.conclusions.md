## Conclusions

In our project, we developed a tool called the Manubot AI Editor.
This tool makes it easier to write and edit academic papers by using artificial intelligence (AI).
Writing these papers can often be a long and difficult process, so we wanted to use technology to help researchers share their findings more effectively.
Our tool works by giving the AI specific instructions on how to improve a manuscript or a particular section of it.
Authors can start this editing process directly from their project's space on GitHub, where the tool suggests changes.
These suggestions come from an AI system known as GPT-3, which we access through OpenAI.
It sends a list of suggested edits for authors to look over.

We've set up some standard settings for the GPT-3 system that work well for a variety of papers and sections.
However, authors can also make adjustments to these settings.
They can choose to focus the editing on certain parts, change how aggressively the AI makes suggestions to fit their needs and budget, and even give the AI custom instructions instead of the pre-set ones.
This flexibility is especially useful for simpler editing tasks that don't need as much complexity. 

Evaluating the effectiveness of these AI-suggested edits can be tricky.
We found that most of the time, the edits improved the text.
However, there were instances where the AI either left out important information or added errors.
The AI also pointed out sections that were hard to edit, which might also be difficult for people to read and understand.


In our study, we used specific instructions to help improve the writing of academic papers with the help of GPT-3, an advanced artificial intelligence system.
Interestingly, the AI was able to spot a mistake in a math equation within the Methods sectionâ€”a mistake that people missed.
However, it struggled to revise summaries without taking out important background information about the research.

There's room to make these AI revisions better, such as by giving the AI more examples to learn from or by teaching it with a collection of academic texts that focus on areas that are usually hard to write about.
Another idea is to use examples of academic papers before and after peer review to teach the AI what changes are commonly made.
Our method worked paragraph by paragraph without the AI understanding the connection between different parts of the text, which was a problem especially for the Results and Methods sections.
Future improvements could include using chatbots that remember what was said before, so they can better revise each paragraph with the whole text in mind.

We are also looking at other AI models like BLOOM, Meta's Llama 2, and Mistral 7B, which are becoming more popular and powerful.
However, these models are not as easy to use as the system from OpenAI that we worked with.
To judge how well the AI did in revising texts, we used a mix of human judgment and automated tools.
New tools and methods are being developed that could help us evaluate the revisions more systematically in the future.
Despite some challenges, we found that the AI often succeeded in making the main points clearer and more straightforward.

While our research used the GPT-3 model from OpenAI, the Manubot AI Editor, the tool we're developing, now also supports newer versions of the AI, GPT 3.5 Turbo and GPT-4, which were released after our study was done.


The use of AI tools in writing scientific papers is a topic of debate.
There are concerns about whether the content produced by these tools is original and who owns it.
For instance, the journal *Nature* has stated that any use of AI in scientific writing needs to be clearly indicated, and the International Conference on Machine Learning (ICML) has banned papers that include content created by AI, although they do allow the use of AI for grammar and spelling checks.
However, our project focuses on improving text that was originally written by a person.
We also make sure to keep a record of all the changes made by both people and AI, ensuring everything is transparent.

Despite these concerns, there are exciting possibilities.
Our work is paving the way for a future where humans and machines work together to write academic papers.
Writing scientific articles requires a specific style, which can make the process time-consuming and difficult, especially when trying to figure out the best way to present a result or discovery.
As machines get better at helping with the writing process, researchers can spend more time thinking about what they want to say rather than how to say it.
This could lead to a future where research is more about the quality of ideas and the ability to conduct experiments, potentially making the field more productive and fair.
